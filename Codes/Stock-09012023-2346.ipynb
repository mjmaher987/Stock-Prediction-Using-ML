{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmaher987/Stock-Prediction-Using-ML/blob/main/Codes/Stock-09012023-2346.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdxuJJpkazAS"
      },
      "source": [
        "# Stock Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XINOdZRawOH"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "whfEf41xG0hA",
        "outputId": "c6192d80-c731-43fe-8ba0-6f368893e22a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, Reshape, Flatten, LSTM\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsJNaLsnbcH3"
      },
      "source": [
        "## Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ApvOxadJbdjV"
      },
      "outputs": [],
      "source": [
        "Configs = {\n",
        "    \"training_percent\" : 0.8,\n",
        "    \"epoch_number\" : 50,\n",
        "    \"sequence_length\" : 10,\n",
        "    \"num_features\" : 5\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoJA4S1fa-nC"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UGSaLgqXawOR"
      },
      "outputs": [],
      "source": [
        "class ETL:\n",
        "    \"\"\"\n",
        "    ticker: str\n",
        "    period: string\n",
        "    test_size: float betwee 0 and 1\n",
        "    n_input: int\n",
        "    timestep: int\n",
        "    Extracts data for stock with ticker `ticker` from yf api,\n",
        "    splits the data into train and test sets by date,\n",
        "    reshapes the data into np.array of shape [#weeks, 5, 1],\n",
        "    converts our problem into supervised learning problem.\n",
        "    \"\"\"\n",
        "    def __init__(self, ticker, test_size=0.2, period='max', n_input=5, timestep=5) -> None:\n",
        "        self.ticker = ticker\n",
        "        self.period = period\n",
        "        self.test_size = test_size\n",
        "        self.n_input = n_input\n",
        "        self.df = self.extract_historic_data()\n",
        "        self.timestep = timestep\n",
        "        self.train, self.test = self.etl()\n",
        "        self.X_train, self.y_train = self.to_supervised(self.train)\n",
        "        self.X_test, self.y_test = self.to_supervised(self.test)\n",
        "\n",
        "    def get_history_from_yf(self):\n",
        "        t = yf.Ticker(self.ticker)\n",
        "        return t.history(period=self.period)\n",
        "\n",
        "    def extract_historic_data(self) -> pd.Series:\n",
        "        \"\"\"\n",
        "        gets historical data from yf api.\n",
        "        \"\"\"\n",
        "        t = yf.Ticker(self.ticker)\n",
        "        history = t.history(period=self.period)\n",
        "        return history.Close\n",
        "\n",
        "    def split_data(self) -> tuple:\n",
        "        \"\"\"\n",
        "        Splits our pd.Series into train and test series with\n",
        "        test series representing test_size * 100 % of data.\n",
        "        \"\"\"\n",
        "        data = self.extract_historic_data()\n",
        "        if len(data) != 0:\n",
        "            train_idx = round(len(data) * (1-self.test_size))\n",
        "            train = data[:train_idx]\n",
        "            test = data[train_idx:]\n",
        "            train = np.array(train)\n",
        "            test = np.array(test)\n",
        "            return train[:, np.newaxis], test[:, np.newaxis]\n",
        "        else:\n",
        "            raise Exception('Data set is empty, cannot split.')\n",
        "\n",
        "    def window_and_reshape(self, data) -> np.array:\n",
        "        \"\"\"\n",
        "        Reformats data into shape our model needs,\n",
        "        namely, [# samples, timestep, # feautures]\n",
        "        samples\n",
        "        \"\"\"\n",
        "        NUM_FEATURES = 1\n",
        "        samples = int(data.shape[0] / self.timestep)\n",
        "        result = np.array(np.array_split(data, samples))\n",
        "        return result.reshape((samples, self.timestep, NUM_FEATURES))\n",
        "\n",
        "    def transform(self, train, test) -> np.array:\n",
        "        train_remainder = train.shape[0] % self.timestep\n",
        "        test_remainder = test.shape[0] % self.timestep\n",
        "        if train_remainder != 0 and test_remainder != 0:\n",
        "            train = train[train_remainder:]\n",
        "            test = test[test_remainder:]\n",
        "        elif train_remainder != 0:\n",
        "            train = train[train_remainder:]\n",
        "        elif test_remainder != 0:\n",
        "            test = test[test_remainder:]\n",
        "        return self.window_and_reshape(train), self.window_and_reshape(test)\n",
        "\n",
        "    def etl(self) -> tuple[np.array, np.array]:\n",
        "        \"\"\"\n",
        "        Runs complete ETL\n",
        "        \"\"\"\n",
        "        train, test = self.split_data()\n",
        "        return self.transform(train, test)\n",
        "\n",
        "    def to_supervised(self, train, n_out=5) -> tuple:\n",
        "        \"\"\"\n",
        "        Converts our time series prediction problem to a\n",
        "        supervised learning problem.\n",
        "        \"\"\"\n",
        "        # flatted the data\n",
        "        data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "        X, y = [], []\n",
        "        in_start = 0\n",
        "        # step over the entire history one time step at a time\n",
        "        for _ in range(len(data)):\n",
        "            # define the end of the input sequence\n",
        "            in_end = in_start + self.n_input\n",
        "            out_end = in_end + n_out\n",
        "            # ensure we have enough data for this instance\n",
        "            if out_end <= len(data):\n",
        "                x_input = data[in_start:in_end, 0]\n",
        "                x_input = x_input.reshape((len(x_input), 1))\n",
        "                X.append(x_input)\n",
        "                y.append(data[in_end:out_end, 0])\n",
        "                # move along one time step\n",
        "                in_start += 1\n",
        "        return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CpDaZkggawOV"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "  etl_data = ETL('EURUSD=X')\n",
        "  history = etl_data.get_history_from_yf()\n",
        "\n",
        "  data = pd.DataFrame(\n",
        "      {\n",
        "          'open': pd.Series([x for x in history.Open]),\n",
        "          'high': pd.Series([x for x in history.High]),\n",
        "          'low': pd.Series([x for x in history.Low]),\n",
        "          'close': pd.Series([x for x in history.Close]),\n",
        "          'volume': pd.Series([x for x in history.Volume]),\n",
        "      }\n",
        "  )\n",
        "\n",
        "  # Preprocessing\n",
        "  scaler = MinMaxScaler()\n",
        "  data['close'] = scaler.fit_transform(data['close'].values.reshape(-1, 1))\n",
        "\n",
        "  # Splitting into training and testing sets\n",
        "  train_size = int(Configs['training_percent'] * len(data))\n",
        "  train_data, test_data = data[:train_size], data[train_size:]\n",
        "  return train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MvrocMLWkEVE"
      },
      "outputs": [],
      "source": [
        "def create_seqs(train_data, test_data):\n",
        "  # Define the sequence length\n",
        "  sequence_length = Configs['sequence_length']\n",
        "  def create_sequences(data, sequence_length):\n",
        "      sequences = []\n",
        "      targets = []\n",
        "      for i in range(len(data) - sequence_length):\n",
        "          sequences.append(data[i:i+sequence_length])\n",
        "          targets.append(data.iloc[i+sequence_length])\n",
        "      return np.array(sequences), np.array(targets)\n",
        "  train_sequences, train_targets = create_sequences(train_data, sequence_length)\n",
        "  test_sequences, test_targets = create_sequences(test_data, sequence_length)\n",
        "  return train_sequences, train_targets, test_sequences, test_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LKqESsOcwwr"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZZagfKTJ-1V"
      },
      "source": [
        "### NBEATS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "14tLBzAMfiTa"
      },
      "outputs": [],
      "source": [
        "class NBeatsModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(NBeatsModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten(input_shape=(Configs['sequence_length'], 5))\n",
        "        self.dense = tf.keras.layers.Dense(5)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "def get_nbeats_model():\n",
        "  return NBeatsModel()\n",
        "\n",
        "def run_nbeats(train_sequences, train_targets, test_sequences, test_targets):\n",
        "  nbeats_model = get_nbeats_model()\n",
        "  nbeats_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  nbeats_model.fit(train_sequences, train_targets, epochs=Configs['epoch_number'], batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions_nbeats = nbeats_model.predict(test_sequences)\n",
        "  mse = mean_squared_error(test_targets, predictions_nbeats)\n",
        "  mae = mean_absolute_error(test_targets, predictions_nbeats)\n",
        "  rmse = mean_squared_error(test_targets, predictions_nbeats, squared=False)\n",
        "  print('--------------------------------\\nNBeats')\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  return predictions_nbeats, mse, mae, rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhHMx5QtKDDz"
      },
      "source": [
        "### NHits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ARgE_1C1KEX5"
      },
      "outputs": [],
      "source": [
        "def build_nhits(input_shape, output_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(output_shape)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def run_nhits(train_sequences, train_targets, test_sequences, test_targets):\n",
        "  nhits_model = build_nhits((Configs['sequence_length'], 5), 5)\n",
        "  nhits_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  nhits_model.fit(train_sequences, train_targets, epochs=Configs['epoch_number'], batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "\n",
        "  nhits_predictions = nhits_model.predict(test_sequences)\n",
        "  mse = mean_squared_error(test_targets, nhits_predictions)\n",
        "  mae = mean_absolute_error(test_targets, nhits_predictions)\n",
        "  rmse = mean_squared_error(test_targets, nhits_predictions, squared=False)\n",
        "  print('--------------------------------\\nNHits')\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  return nhits_predictions, mse, mae, rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTwNc2NkLc1b"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JZM5QunILfDJ"
      },
      "outputs": [],
      "source": [
        "def run_rnn(train_sequences, train_targets, test_sequences, test_targets):\n",
        "  model_rnn = tf.keras.Sequential([\n",
        "      tf.keras.layers.SimpleRNN(64, input_shape=(Configs['sequence_length'], 5), return_sequences=False),\n",
        "      tf.keras.layers.Dense(5)\n",
        "  ])\n",
        "\n",
        "  model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  model_rnn.fit(train_sequences, train_targets, epochs=Configs['epoch_number'], batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "\n",
        "  # Make predictions\n",
        "  predictions_rnn = model_rnn.predict(test_sequences)\n",
        "  mse = mean_squared_error(test_targets, predictions_rnn)\n",
        "  mae = mean_absolute_error(test_targets, predictions_rnn)\n",
        "  rmse = mean_squared_error(test_targets, predictions_rnn, squared=False)\n",
        "  print('--------------------------------\\nRNN')\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  return predictions_rnn, mse, mae, rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5HneAVvagpC"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TQL3cHiCakCs"
      },
      "outputs": [],
      "source": [
        "def run_lstm(train_sequences, train_targets, test_sequences, test_targets):\n",
        "  lstm_model = tf.keras.Sequential([\n",
        "      tf.keras.layers.LSTM(64, input_shape=(Configs['sequence_length'], 5), return_sequences=False),\n",
        "      tf.keras.layers.Dense(5)\n",
        "  ])\n",
        "\n",
        "  lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "  lstm_model.fit(train_sequences, train_targets, epochs=Configs['epoch_number'], batch_size=32, verbose=0)\n",
        "\n",
        "\n",
        "  lstm_predictions = lstm_model.predict(test_sequences)\n",
        "  mse = mean_squared_error(test_targets, lstm_predictions)\n",
        "  mae = mean_absolute_error(test_targets, lstm_predictions)\n",
        "  rmse = mean_squared_error(test_targets, lstm_predictions, squared=False)\n",
        "  print('--------------------------------\\nLSTM')\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  return lstm_predictions, mse, mae, rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIOYM2fSbeIQ"
      },
      "source": [
        "### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H0IjyM3bawOj"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0, epsilon=1e-6, attention_axes=None, kernel_size=1):\n",
        "  \"\"\"\n",
        "  Creates a single transformer block.\n",
        "  \"\"\"\n",
        "  x = layers.LayerNormalization(epsilon=epsilon)(inputs)\n",
        "  x = layers.MultiHeadAttention(\n",
        "      key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
        "      attention_axes=attention_axes\n",
        "      )(x, x)\n",
        "  x = layers.Dropout(dropout)(x)\n",
        "  res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "  x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
        "  x = layers.Conv1D(filters=ff_dim, kernel_size=kernel_size, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(dropout)(x)\n",
        "  x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=kernel_size)(x)\n",
        "  return x + res\n",
        "\n",
        "def build_transfromer(head_size, num_heads, ff_dim, num_trans_blocks, mlp_units, dropout=0, mlp_dropout=0, attention_axes=None, epsilon=1e-6, kernel_size=1):\n",
        "  \"\"\"\n",
        "  Creates final model by building many transformer blocks.\n",
        "  \"\"\"\n",
        "  n_timesteps, n_features, n_outputs = Configs['sequence_length'], 5, 5\n",
        "  inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
        "  x = inputs\n",
        "  for _ in range(num_trans_blocks):\n",
        "    x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout, attention_axes=attention_axes, kernel_size=kernel_size, epsilon=epsilon)\n",
        "\n",
        "  x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "  for dim in mlp_units:\n",
        "    x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(mlp_dropout)(x)\n",
        "\n",
        "  outputs = layers.Dense(n_outputs)(x)\n",
        "  return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "def fit_transformer(transformer: tf.keras.Model, train_sequences, train_targets):\n",
        "  \"\"\"\n",
        "  Compiles and fits our transformer.\n",
        "  \"\"\"\n",
        "  transformer.compile(\n",
        "    loss=\"mse\",\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\"mae\", 'mape']\n",
        "  )\n",
        "\n",
        "  callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\n",
        "  hist = transformer.fit(train_sequences, train_targets, batch_size=32, epochs=Configs['epoch_number'], verbose=0, callbacks=callbacks)\n",
        "  return hist\n",
        "\n",
        "def run_transformer(train_sequences, train_targets, test_sequences, test_targets):\n",
        "  transformer_model = build_transfromer(head_size=128, num_heads=4, ff_dim=2, num_trans_blocks=4, mlp_units=[256], mlp_dropout=0.10, dropout=0.10, attention_axes=1)\n",
        "  hist = fit_transformer(transformer_model, train_sequences, train_targets)\n",
        "  transformer_predictions = transformer_model.predict(test_sequences)\n",
        "  mse = mean_squared_error(test_targets, transformer_predictions)\n",
        "  mae = mean_absolute_error(test_targets, transformer_predictions)\n",
        "  rmse = mean_squared_error(test_targets, transformer_predictions, squared=False)\n",
        "  print('--------------------------------\\nTransformer')\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  return transformer_predictions, mse, mae, rmse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCSaEKDlcpoB"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zyOBm5MoX1Wp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def visualize_all(test_targets, predictions_nbeats, nhits_predictions, predictions_rnn, lstm_predictions, transformer_predictions, folder):\n",
        "  test_targets_close = [test_target[3] for test_target in test_targets]\n",
        "  nbeats_close = [predictions_nbit[3] for predictions_nbit in predictions_nbeats]\n",
        "  nhits_close = [nhits_prediction[3] for nhits_prediction in nhits_predictions]\n",
        "  rnn_close = [prediction_rnn[3] for prediction_rnn in predictions_rnn]\n",
        "  lstm_close = [lstm_prediction[3] for lstm_prediction in lstm_predictions]\n",
        "  transformer_close = [transformer_prediction[3] for transformer_prediction in transformer_predictions]\n",
        "\n",
        "  plt.figure(figsize=(24, 18), dpi=400)\n",
        "  plt.plot(test_targets_close, label='Actual')\n",
        "  plt.plot(nbeats_close, label='NBeats')\n",
        "  plt.plot(nhits_close, label='NHits')\n",
        "  plt.plot(rnn_close, label='RNN')\n",
        "  plt.plot(lstm_close, label='LSTM')\n",
        "  plt.plot(transformer_close, label='Transformer')\n",
        "  plt.legend()\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder):\n",
        "    os.mkdir(folder)\n",
        "\n",
        "  plt.savefig(os.path.join(folder, 'plot.png'))\n",
        "\n",
        "\n",
        "def visualize_one(test_targets_close, predicts_close, folder, name):\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.plot(test_targets_close, label='Actual')\n",
        "  plt.plot(predicts_close, label=name)\n",
        "  plt.legend()\n",
        "  plt.savefig(os.path.join(folder, name + '.png'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def start_simulation(train_data, test_data):\n",
        "   print('--------------------------')\n",
        "   print('--------------------------')\n",
        "   print('--------------------------')\n",
        "   print('Configs:')\n",
        "   print('Sequence Length:' + str(Configs['sequence_length']))\n",
        "   print('Epoch Number: ' + str(Configs['epoch_number']))\n",
        "\n",
        "   start_time = time.time()\n",
        "\n",
        "\n",
        "   train_sequences, train_targets, test_sequences, test_targets = create_seqs(train_data, test_data)\n",
        "\n",
        "   preds_nbeats, mse_nbeats, mae_nbeats, rmse_nbeats = run_nbeats(train_sequences, train_targets, test_sequences, test_targets)\n",
        "   preds_nhits, mse_nhits, mae_nhits, rmse_nbeats = run_nhits(train_sequences, train_targets, test_sequences, test_targets)\n",
        "   preds_rnn, mse_rnn, mae_rnn, rmse_rnn = run_rnn(train_sequences, train_targets, test_sequences, test_targets)\n",
        "   preds_lstm, mse_lstm, mae_lstm, rmse_lstm = run_lstm(train_sequences, train_targets, test_sequences, test_targets)\n",
        "   preds_transformer, mse_transformer, mae_transformer, rmse_transformer = run_transformer(train_sequences, train_targets, test_sequences, test_targets)\n",
        "\n",
        "   end_time = time.time()\n",
        "   simulation_time = end_time - start_time\n",
        "   print(f\"The simulation took {simulation_time} seconds to run.\")\n",
        "\n",
        "   folder = \"/content/drive/MyDrive/Experiments/\" + str(Configs['epoch_number']) + '_' + str(Configs['sequence_length'])\n",
        "\n",
        "   visualize_all(test_targets, preds_nbeats, preds_nhits, preds_rnn, preds_lstm, preds_transformer, folder)\n",
        "\n",
        "   test_targets_close = [test_target[3] for test_target in test_targets]\n",
        "   nbeats_close = [predictions_nbit[3] for predictions_nbit in preds_nbeats]\n",
        "   nhits_close = [nhits_prediction[3] for nhits_prediction in preds_nhits]\n",
        "   rnn_close = [prediction_rnn[3] for prediction_rnn in preds_rnn]\n",
        "   lstm_close = [lstm_prediction[3] for lstm_prediction in preds_lstm]\n",
        "   transformer_close = [transformer_prediction[3] for transformer_prediction in preds_transformer]\n",
        "\n",
        "   visualize_one(test_targets_close, nbeats_close, folder, 'NBeats')\n",
        "   visualize_one(test_targets_close, nhits_close, folder, 'NHits')\n",
        "   visualize_one(test_targets_close, rnn_close, folder, 'RNN')\n",
        "   visualize_one(test_targets_close, lstm_close, folder, 'LSTM')\n",
        "   visualize_one(test_targets_close, transformer_close, folder, 'Transformer')\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Experiments/\"\n",
        "if not os.path.exists(folder):\n",
        "  os.mkdir(folder)\n",
        "\n",
        "train_data, test_data = preprocess()\n",
        "seqs = [2, 5, 10, 50]\n",
        "epochs = [10, 50, 100, 200]\n",
        "for seq in seqs:\n",
        "  for epoch in epochs:\n",
        "    Configs['epoch_number'] = epoch\n",
        "    Configs['sequence_length'] = seq\n",
        "    start_simulation(train_data, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLBpSV5C5Luq",
        "outputId": "f2122c31-8731-4cc8-c4bf-8164fb74bac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:2\n",
            "Epoch Number: 10\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 0.009725912731752811\n",
            "Mean Absolute Error: 0.08241733537309906\n",
            "Root Mean Squared Error: 0.08654909527163698\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 0.00012395235586687049\n",
            "Mean Absolute Error: 0.005331743865119399\n",
            "Root Mean Squared Error: 0.008326176158181074\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 0.00018687849560518978\n",
            "Mean Absolute Error: 0.009750583174286495\n",
            "Root Mean Squared Error: 0.01269763100166765\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 8.83010746499111e-05\n",
            "Mean Absolute Error: 0.006036458233529071\n",
            "Root Mean Squared Error: 0.007670908120358463\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "--------------------------------\n",
            "Transformer\n",
            "Mean Squared Error: 0.0007820178411302913\n",
            "Mean Absolute Error: 0.016171927195087515\n",
            "Root Mean Squared Error: 0.022712460141350265\n",
            "The simulation took 63.74918246269226 seconds to run.\n",
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:2\n",
            "Epoch Number: 50\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 0.00017918194628946727\n",
            "Mean Absolute Error: 0.00883311350334739\n",
            "Root Mean Squared Error: 0.010311928706256994\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 4.1917547066015513e-05\n",
            "Mean Absolute Error: 0.004198588967442964\n",
            "Root Mean Squared Error: 0.0057461938973572425\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 0.00010766483621898096\n",
            "Mean Absolute Error: 0.007876852058791881\n",
            "Root Mean Squared Error: 0.009692807690546234\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 7.55577326560567e-05\n",
            "Mean Absolute Error: 0.006247790916604932\n",
            "Root Mean Squared Error: 0.0076401598446236545\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "--------------------------------\n",
            "Transformer\n",
            "Mean Squared Error: 0.00021151900019346007\n",
            "Mean Absolute Error: 0.009235792593028137\n",
            "Root Mean Squared Error: 0.012442985589752967\n",
            "The simulation took 308.273396730423 seconds to run.\n",
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:2\n",
            "Epoch Number: 100\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 4.170113267882883e-05\n",
            "Mean Absolute Error: 0.004756067586688726\n",
            "Root Mean Squared Error: 0.006110804134324349\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 8.728475145278118e-05\n",
            "Mean Absolute Error: 0.006919980863455927\n",
            "Root Mean Squared Error: 0.008553129009954455\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 9.702698111224519e-05\n",
            "Mean Absolute Error: 0.007480174453891289\n",
            "Root Mean Squared Error: 0.008775752654567742\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 7.124061091571111e-05\n",
            "Mean Absolute Error: 0.006342948682950084\n",
            "Root Mean Squared Error: 0.007557185271976907\n",
            "32/32 [==============================] - 1s 8ms/step\n",
            "--------------------------------\n",
            "Transformer\n",
            "Mean Squared Error: 0.0002352724683160737\n",
            "Mean Absolute Error: 0.009662435746687056\n",
            "Root Mean Squared Error: 0.013600081430695627\n",
            "The simulation took 493.4439253807068 seconds to run.\n",
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:2\n",
            "Epoch Number: 200\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 5.1671721978174836e-05\n",
            "Mean Absolute Error: 0.005127124322417997\n",
            "Root Mean Squared Error: 0.006285020989589567\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 9.477801981961582e-05\n",
            "Mean Absolute Error: 0.004984092996005729\n",
            "Root Mean Squared Error: 0.007623728840228014\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 0.0002367444875817142\n",
            "Mean Absolute Error: 0.011732718423382341\n",
            "Root Mean Squared Error: 0.012725526603938173\n",
            "32/32 [==============================] - 1s 3ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 6.056890330073031e-05\n",
            "Mean Absolute Error: 0.005631615270254593\n",
            "Root Mean Squared Error: 0.006947937208709021\n",
            "32/32 [==============================] - 1s 7ms/step\n",
            "--------------------------------\n",
            "Transformer\n",
            "Mean Squared Error: 0.0003531004344908161\n",
            "Mean Absolute Error: 0.01348299189367504\n",
            "Root Mean Squared Error: 0.016566630086863012\n",
            "The simulation took 970.2323155403137 seconds to run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a8c6ba36e796>:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(8, 6), dpi=80)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:5\n",
            "Epoch Number: 10\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 0.007650107612028718\n",
            "Mean Absolute Error: 0.06712035891969731\n",
            "Root Mean Squared Error: 0.07157857674729001\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 0.0002017875709521904\n",
            "Mean Absolute Error: 0.00776775622630015\n",
            "Root Mean Squared Error: 0.011584879519960956\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 0.0001683997342380746\n",
            "Mean Absolute Error: 0.009784722596073525\n",
            "Root Mean Squared Error: 0.012280191686465727\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 0.0001106943710479305\n",
            "Mean Absolute Error: 0.007414731941169837\n",
            "Root Mean Squared Error: 0.009682135838410679\n",
            "32/32 [==============================] - 1s 16ms/step\n",
            "--------------------------------\n",
            "Transformer\n",
            "Mean Squared Error: 7.643183938662074e-05\n",
            "Mean Absolute Error: 0.006087411917281084\n",
            "Root Mean Squared Error: 0.00803850804972345\n",
            "The simulation took 122.96642994880676 seconds to run.\n",
            "--------------------------\n",
            "--------------------------\n",
            "--------------------------\n",
            "Configs:\n",
            "Sequence Length:5\n",
            "Epoch Number: 50\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NBeats\n",
            "Mean Squared Error: 8.661586872939057e-05\n",
            "Mean Absolute Error: 0.007079636204304162\n",
            "Root Mean Squared Error: 0.00888736286416494\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "--------------------------------\n",
            "NHits\n",
            "Mean Squared Error: 0.00012230270238521325\n",
            "Mean Absolute Error: 0.006980635212638342\n",
            "Root Mean Squared Error: 0.009461951341259805\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "--------------------------------\n",
            "RNN\n",
            "Mean Squared Error: 0.00015160242877097963\n",
            "Mean Absolute Error: 0.010924814305607978\n",
            "Root Mean Squared Error: 0.012139336419599123\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "--------------------------------\n",
            "LSTM\n",
            "Mean Squared Error: 9.814825689318002e-05\n",
            "Mean Absolute Error: 0.008196580619348763\n",
            "Root Mean Squared Error: 0.009574389497448016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnm3hgZlvHA5"
      },
      "source": [
        "### NBeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w145cP0BvI0o"
      },
      "outputs": [],
      "source": [
        "visualize_one(test_targets_close, nbeats_close)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBOv3KJaz0GM"
      },
      "source": [
        "### NHits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhI3gZkhz1Wk"
      },
      "outputs": [],
      "source": [
        "visualize_one(test_targets_close, nhits_close)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMuhHwhPo1Sp"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ8lEiZMv_Tw"
      },
      "outputs": [],
      "source": [
        "visualize_one(test_targets_close, rnn_close)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjK_jCBl0O8R"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jYKjSz10Q5q"
      },
      "outputs": [],
      "source": [
        "visualize_one(test_targets_close, lstm_close)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5mpdOMdB1Q"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBBtUy9kawOl"
      },
      "outputs": [],
      "source": [
        "visualize_one(test_targets_close, transformer_close)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b747sLUawOm"
      },
      "source": [
        "Save and serialize models for the bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85EiQmMWawOn"
      },
      "outputs": [],
      "source": [
        "def save_models():\n",
        "  # save models for bot usage\n",
        "  nbeats_model.save('./model_dumps/nbeats.tf')\n",
        "  nhits_model.save('./model_dumps/nhits.keras')\n",
        "  model_rnn.save('./model_dumps/rnn.keras')\n",
        "  lstm_model.save('./model_dumps/lstm.keras')\n",
        "  transformer_model.save('./model_dumps/transformer.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}