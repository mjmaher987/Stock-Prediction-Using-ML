{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzGfP9DEb4Qpv5309tKcE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmaher987/Stock-Prediction-Using-ML/blob/main/Stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NBEATS"
      ],
      "metadata": {
        "id": "MZZagfKTJ-1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "whfEf41xG0hA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load your DataFrame\n",
        "data = pd.read_csv('EURUSD_5min.csv')\n",
        "\n",
        "# Preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "data['close'] = scaler.fit_transform(data['close'].values.reshape(-1, 1))\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "train_size = int(0.8 * len(data))\n",
        "train_data, test_data = data[:train_size], data[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
      ],
      "metadata": {
        "id": "1lrAm8-YdWhO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for N-BEATS\n",
        "window_size = 10\n",
        "X, y = [], []\n",
        "for i in range(len(data) - window_size):\n",
        "    X.append(data['close'][i:i+window_size])\n",
        "    y.append(data['close'][i+window_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "train_size = int(0.8 * len(X))\n",
        "train_X, test_X = X[:train_size], X[train_size:]\n",
        "train_y, test_y = y[:train_size], y[train_size:]\n",
        "\n",
        "# Build N-BEATS model\n",
        "def build_nbeats(input_shape, output_shape, num_blocks=4, num_neurons=128):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    forecasts = []\n",
        "    for _ in range(num_blocks):\n",
        "        for _ in range(4):  # Directly following the N-BEATS architecture\n",
        "            x = Dense(num_neurons, activation='relu')(x)\n",
        "        forecast = Dense(output_shape[0])(x)\n",
        "        forecasts.append(forecast)\n",
        "    outputs = forecasts[0]  # Use the forecast from the first block as output\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "input_shape = (window_size, 1)\n",
        "output_shape = (1,)\n",
        "nbeats_model = build_nbeats(input_shape, output_shape)\n",
        "nbeats_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train N-BEATS model\n",
        "nbeats_model.fit(train_X, train_y, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "test_predictions = nbeats_model.predict(test_X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14tLBzAMfiTa",
        "outputId": "bcf5e711-468c-44a3-91bc-37891ee40dab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 5s 12ms/step - loss: 0.0854\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0590\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0593\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0595\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0586\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0591\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0583\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0583\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0586\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0589\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0586\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0584\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0588\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0582\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0583\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0589\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0583\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0581\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0585\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0583\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0586\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0588\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0583\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0581\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0582\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0585\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0583\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0582\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0582\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0581\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0582\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0581\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0585\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0582\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0584\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0583\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0583\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0582\n",
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_test_predictions = test_predictions[:, -1, :]"
      ],
      "metadata": {
        "id": "ILOv3ECcfC-x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate MAE and RMSE\n",
        "# print(test_y.shape)\n",
        "# print(reshaped_test_predictions.shape)\n",
        "mae = mean_absolute_error(test_y, reshaped_test_predictions)\n",
        "rmse = mean_squared_error(test_y, reshaped_test_predictions, squared=False)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-OY7UI1d_mm",
        "outputId": "a81945c0-7942-46d5-b77a-5980975c591b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.25914657814572256\n",
            "Root Mean Squared Error: 0.2741693059599835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NHEATS"
      ],
      "metadata": {
        "id": "zhHMx5QtKDDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load and preprocess your data\n",
        "# data = pd.read_csv('trading_data.csv')\n",
        "# scaler = MinMaxScaler()\n",
        "# data['close'] = scaler.fit_transform(data['close'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = data[['open', 'high', 'low', 'volume']].values\n",
        "y = data['close'].values\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "train_size = int(0.7 * len(X))\n",
        "val_size = int(0.15 * len(X))\n",
        "train_X, test_X, train_y, test_y = X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n",
        "train_X, val_X, train_y, val_y = train_X[:train_size - val_size], train_X[train_size - val_size:], \\\n",
        "                                  train_y[:train_size - val_size], train_y[train_size - val_size:]\n",
        "\n",
        "# Normalize data\n",
        "scaler_X = MinMaxScaler()\n",
        "train_X = scaler_X.fit_transform(train_X)\n",
        "val_X = scaler_X.transform(val_X)\n",
        "test_X = scaler_X.transform(test_X)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "train_y = scaler_y.fit_transform(train_y.reshape(-1, 1)).flatten()\n",
        "val_y = scaler_y.transform(val_y.reshape(-1, 1)).flatten()\n",
        "test_y = scaler_y.transform(test_y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# NHITS Model\n",
        "def build_nhits(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "nhits_model = build_nhits(train_X.shape[1])\n",
        "nhits_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "nhits_model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(val_X, val_y), verbose=1)\n",
        "\n",
        "nhits_predictions = nhits_model.predict(test_X)\n",
        "\n",
        "# Calculate MAE and RMSE for NHITS\n",
        "nhits_mae = mean_absolute_error(test_y, nhits_predictions)\n",
        "nhits_rmse = mean_squared_error(test_y, nhits_predictions, squared=False)\n",
        "print(f\"NHITS Mean Absolute Error: {nhits_mae}\")\n",
        "print(f\"NHITS Root Mean Squared Error: {nhits_rmse}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARgE_1C1KEX5",
        "outputId": "fe6eb7e9-a727-45ea-a00f-875af2ee3589"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "86/86 [==============================] - 1s 5ms/step - loss: 0.0515 - val_loss: 1.8923e-04\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 4.6590e-05 - val_loss: 3.6330e-05\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.9555e-05 - val_loss: 2.3878e-05\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.6863e-05 - val_loss: 2.3510e-05\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.4796e-05 - val_loss: 2.2684e-05\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.4372e-05 - val_loss: 2.4931e-05\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.4061e-05 - val_loss: 2.2347e-05\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.4340e-05 - val_loss: 3.1715e-05\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.4540e-05 - val_loss: 2.6735e-05\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.6174e-05 - val_loss: 4.4216e-05\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.4016e-05 - val_loss: 3.2519e-05\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.2479e-05 - val_loss: 2.2616e-05\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.3669e-05 - val_loss: 2.0850e-05\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.1811e-05 - val_loss: 2.2413e-05\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.2288e-05 - val_loss: 2.1662e-05\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.1294e-05 - val_loss: 1.9972e-05\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.1331e-05 - val_loss: 2.3368e-05\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.1563e-05 - val_loss: 2.1604e-05\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.2651e-05 - val_loss: 1.9122e-05\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 2.2017e-05 - val_loss: 1.8868e-05\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 1.9363e-05 - val_loss: 2.3010e-05\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 1.8614e-05 - val_loss: 1.7761e-05\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.4101e-05 - val_loss: 2.0401e-05\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.2016e-05 - val_loss: 1.7764e-05\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8784e-05 - val_loss: 1.7599e-05\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8470e-05 - val_loss: 1.8724e-05\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8241e-05 - val_loss: 1.6996e-05\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.1180e-05 - val_loss: 2.0131e-05\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 1.7574e-05 - val_loss: 1.6805e-05\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.0365e-05 - val_loss: 2.1287e-05\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8911e-05 - val_loss: 2.0667e-05\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8136e-05 - val_loss: 1.6388e-05\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.1201e-05 - val_loss: 1.6084e-05\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8836e-05 - val_loss: 1.5632e-05\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.7603e-05 - val_loss: 2.2006e-05\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 1.8256e-05 - val_loss: 2.5791e-05\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8751e-05 - val_loss: 1.8943e-05\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8328e-05 - val_loss: 1.6021e-05\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.7066e-05 - val_loss: 1.5468e-05\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.7599e-05 - val_loss: 1.4553e-05\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.5783e-05 - val_loss: 1.4731e-05\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.5246e-05 - val_loss: 1.9787e-05\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.9762e-05 - val_loss: 1.3956e-05\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.8041e-05 - val_loss: 1.4702e-05\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.5953e-05 - val_loss: 2.7605e-05\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 1.4904e-05 - val_loss: 1.9172e-05\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.6842e-05 - val_loss: 1.7669e-05\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 1.5412e-05 - val_loss: 1.4132e-05\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.6687e-05 - val_loss: 2.3110e-05\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 1.5736e-05 - val_loss: 1.2983e-05\n",
            "47/47 [==============================] - 0s 1ms/step\n",
            "NHITS Mean Absolute Error: 0.0030076416755709114\n",
            "NHITS Root Mean Squared Error: 0.004417942136340275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN"
      ],
      "metadata": {
        "id": "QTwNc2NkLc1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model\n",
        "def build_rnn(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.LSTM(64, input_shape=(input_shape, 1), activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "train_X_rnn = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
        "val_X_rnn = val_X.reshape(val_X.shape[0], val_X.shape[1], 1)\n",
        "test_X_rnn = test_X.reshape(test_X.shape[0], test_X.shape[1], 1)\n",
        "\n",
        "rnn_model = build_rnn(train_X_rnn.shape[1])\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "rnn_model.fit(train_X_rnn, train_y, epochs=50, batch_size=32, validation_data=(val_X_rnn, val_y), verbose=1)\n",
        "\n",
        "\n",
        "# Evaluate RNN models\n",
        "rnn_predictions = rnn_model.predict(test_X_rnn)\n",
        "\n",
        "# Calculate MAE and RMSE for RNN\n",
        "rnn_mae = mean_absolute_error(test_y, rnn_predictions)\n",
        "rnn_rmse = mean_squared_error(test_y, rnn_predictions, squared=False)\n",
        "print(f\"RNN Mean Absolute Error: {rnn_mae}\")\n",
        "print(f\"RNN Root Mean Squared Error: {rnn_rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZM5QunILfDJ",
        "outputId": "805d5804-955b-4626-d68c-5b68cbbeb63a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "86/86 [==============================] - 2s 8ms/step - loss: 0.1862 - val_loss: 0.0025\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0013\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 4.0841e-04 - val_loss: 2.0742e-04\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 2s 18ms/step - loss: 1.6705e-04 - val_loss: 1.4413e-04\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 1.4508e-04 - val_loss: 1.3523e-04\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 1.3096e-04 - val_loss: 1.5602e-04\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 1.2499e-04 - val_loss: 1.0099e-04\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 1.1088e-04 - val_loss: 9.2638e-05\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 1.0062e-04 - val_loss: 1.5743e-04\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 9.8534e-05 - val_loss: 8.6085e-05\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 9.6773e-05 - val_loss: 9.3228e-05\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 8.6001e-05 - val_loss: 7.8254e-05\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 8.1271e-05 - val_loss: 8.9862e-05\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 7.5561e-05 - val_loss: 7.3975e-05\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 6.9192e-05 - val_loss: 8.2359e-05\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 6.8331e-05 - val_loss: 6.6471e-05\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 5.8888e-05 - val_loss: 6.1109e-05\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 5.7273e-05 - val_loss: 5.6443e-05\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 5.1352e-05 - val_loss: 6.7974e-05\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 5.0051e-05 - val_loss: 5.1131e-05\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 4.2963e-05 - val_loss: 4.7188e-05\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 4.5210e-05 - val_loss: 4.8599e-05\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 4.0891e-05 - val_loss: 4.6981e-05\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 1s 17ms/step - loss: 3.5966e-05 - val_loss: 5.5628e-05\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 3.6969e-05 - val_loss: 4.1757e-05\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.4351e-05 - val_loss: 3.5106e-05\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.1266e-05 - val_loss: 3.4092e-05\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 3.2513e-05 - val_loss: 3.3424e-05\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 3.2152e-05 - val_loss: 3.4268e-05\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 3.1549e-05 - val_loss: 3.3699e-05\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.0990e-05 - val_loss: 3.3887e-05\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.0246e-05 - val_loss: 3.2017e-05\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 4.1667e-05 - val_loss: 4.1781e-05\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.5002e-05 - val_loss: 3.4877e-05\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 3.1242e-05 - val_loss: 3.9680e-05\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 3.1610e-05 - val_loss: 3.1726e-05\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 2.9971e-05 - val_loss: 2.9997e-05\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 3.0817e-05 - val_loss: 3.2767e-05\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 3.1346e-05 - val_loss: 3.2940e-05\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 1s 11ms/step - loss: 3.0455e-05 - val_loss: 3.0395e-05\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 1s 10ms/step - loss: 3.0557e-05 - val_loss: 3.9498e-05\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 3.6619e-05 - val_loss: 4.3720e-05\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.1685e-05 - val_loss: 3.0807e-05\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.0266e-05 - val_loss: 3.6868e-05\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 2.9628e-05 - val_loss: 3.2357e-05\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.2491e-05 - val_loss: 3.2643e-05\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 2.9859e-05 - val_loss: 3.0493e-05\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.0451e-05 - val_loss: 3.0775e-05\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.1865e-05 - val_loss: 3.0079e-05\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.5648e-05 - val_loss: 4.0177e-05\n",
            "47/47 [==============================] - 0s 3ms/step\n",
            "RNN Mean Absolute Error: 0.004437983963140224\n",
            "RNN Root Mean Squared Error: 0.006654418975073334\n"
          ]
        }
      ]
    }
  ]
}